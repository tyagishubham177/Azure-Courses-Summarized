# Examining Autoscale Factors

## Key Points

- **Autoscaling Triggers**: Can be based on schedules or resource usage (CPU, memory, incoming requests).

## What is Autoscaling?
- **Definition**: Adjusts available resources based on demand by scaling in and out.

## Azure App Service Autoscaling
- **Function**: Monitors web app resource metrics, adds/removes web servers as needed.
- **Note**: Does not affect CPU, memory, or storage capacity, only the number of web servers.

## Autoscaling Rules
- **Decision Basis**: Defined rules and thresholds for metrics.
- **Important Consideration**: Carefully define rules to handle genuine traffic vs. DoS attacks.

## When to Consider Autoscaling?
- **Elasticity**: Handles fluctuating activity, e.g., holiday traffic.
- **Availability & Fault Tolerance**: Ensures service requests are acknowledged and handled.
- **Resource-Intensive Processing**: Not ideal; consider manual scaling for large dataset processing.
- **Long-term Growth**: Manual scaling may be more cost-effective for anticipated growth.
- **Number of Instances**: Fewer instances mean less capacity to handle increased workload even with autoscaling.

# Autoscale Factors

## Key Points

- **Purpose**: Adjusts resources based on demand to handle peak times and manage costs.
- **Methods**: Scale based on metrics or a schedule.

## Autoscaling and the App Service Plan
- **Function**: Starts new hardware instances as defined by the App Service Plan.
- **Limits**: Instance limits to prevent runaway autoscaling; higher limits in more expensive plans.
- **Support**: Not all pricing tiers support autoscaling.

## Autoscale Conditions
- **Options**:
  - **Metric-Based**: Scale based on metrics like disk queue length or HTTP requests.
  - **Schedule-Based**: Scale to a specific instance count according to a schedule.

## Metrics for Autoscale Rules
- **Common Metrics**:
  - **CPU Percentage**: Indicates CPU utilization.
  - **Memory Percentage**: Measures memory occupancy.
  - **Disk Queue Length**: Outstanding I/O requests.
  - **Http Queue Length**: Client requests awaiting processing.
  - **Data In/Out**: Bytes received/sent by instances.
- **Other Metrics**: Can include metrics from other Azure services (e.g., Service Bus Queue).

## How Autoscale Rules Analyze Metrics
- **Steps**:
  1. **Time Grain**: Aggregates metric values over a short period (e.g., 1 minute).
  2. **Duration**: Further aggregates these values over a longer period (e.g., 10 minutes).

## Autoscale Actions
- **Types**: Scale-out (increase instances) or scale-in (reduce instances).
- **Cool Down Period**: Prevents rapid re-triggering of autoscale actions (minimum 5 minutes).

## Pairing and Combining Autoscale Rules
- **Paired Rules**: Define both scale-out and scale-in rules for the same metric.
- **Combined Rules**: Multiple rules can exist in a single condition; scale-out if any met, scale-in if all met.

# Enabling Autoscale in App Service

## Steps to Enable Autoscaling

### Step 1: Navigate to Scale Out Settings
- **Location**: App Service Plan in Azure portal
- **Navigation**: Settings group -> Scale out (App Service plan)

### Note
- **Pricing Tiers**: 
  - Development tiers (F1, D1): Single instance or manual scaling
  - B1 tier: Manual scaling only
  - **Required**: Scale up to S1 or P level production tiers for autoscaling

### Step 2: Enable Custom Autoscale
- **Default**: App Service Plan uses manual scaling
- **Action**: Select Custom autoscale to reveal condition groups for scale settings

### Enabling Autoscale
1. **Navigate to App Service Plan**: Azure portal
2. **Select**: Scale out (App Service plan)
3. **Choose**: Custom autoscale

## Add Scale Conditions

### Default Scale Condition
- **Purpose**: Active when no other scale conditions are active

### Custom Scale Conditions
- **Types**: Metric-based or instance count-based
- **Options**: Minimum and maximum instances (limits defined by pricing tier)
- **Schedules**: Can include schedules for when conditions apply

## Create Scale Rules

### Adding Custom Rules
1. **Navigate**: Add a rule link
2. **Define Criteria**: 
   - Trigger conditions for autoscale action
   - Autoscale action (scale out or scale in)
   - Metrics, aggregations, operators, thresholds

## Monitor Autoscaling Activity

### Run History Chart
- **Function**: Shows instance variations over time
- **Details**: Displays autoscale conditions causing each change

### Correlation
- **Run History Chart**: Used with metrics on Overview page
- **Purpose**: Correlate autoscaling events with resource utilization

# Autoscale Best Practices

## Key Concepts
- **Horizontal Scaling**: Scaling out increases instances; scaling in decreases instances.
- **Instance Limits**: Each autoscale setting has maximum, minimum, and default instance values.
- **Metric Thresholds**: Autoscale actions are triggered based on metric thresholds.

## Best Practices

### 1. Distinguish Maximum and Minimum Values
- **Ensure Margin**: Maintain an adequate margin between maximum and minimum instance counts to allow for scaling actions.

### 2. Choose Appropriate Statistics
- **Diagnostics Metrics**: Use statistics like Average, Minimum, Maximum, and Total. Commonly, Average is used.

### 3. Set Practical Thresholds
- **Avoid Same Thresholds**: Different thresholds for scale-out and scale-in to prevent flapping (e.g., scale-out at CPU ≥ 80%, scale-in at CPU ≤ 60%).

### 4. Avoid Conflicting Rules
- **Example of Conflict**:
  - Scale out if Thread Count ≥ 600
  - Scale in if Thread Count ≤ 600
  - **Better Approach**: Scale out at higher threshold (e.g., Thread Count ≥ 700) and scale in at lower threshold (e.g., Thread Count ≤ 500).

### 5. Estimate Scale-In Effects
- **Avoid Flapping**: Autoscale estimates the impact of scaling in to prevent back-and-forth actions.

### 6. Use Multiple Rules Wisely
- **Scale-Out**: Triggers if any rule is met.
- **Scale-In**: Requires all rules to be met.

### 7. Safe Default Instance Count
- **Default**: Set a safe default instance count for when metrics are unavailable.

### 8. Configure Notifications
- **Activity Log Alerts**: Monitor autoscale actions and engine health through email, SMS, or webhooks.

## Example Rules

| Action            | Rule                                                  |
|-------------------|-------------------------------------------------------|
| **Scale Out**     | CPU% ≥ 80 or Memory ≥ 75%                             |
| **Scale In**      | CPU% ≤ 60 and Memory ≤ 50%                            |
| **Safe Default**  | Set default instance count to handle average workload |

### Case Study: CPU Thresholds

1. **Initial State**: 2 instances, CPU rises to 80% → Scale out to 3 instances.
2. **Scale-In Evaluation**:
   - CPU falls to 60% → Estimation prevents scaling in to avoid flapping.
   - Further drop to 50% → Successfully scale in to 2 instances.

### Notifications Setup

- **Conditions**:
  - Scale operation issued.
  - Scale action completed or failed.
  - Metrics unavailable or recovered.


## Summary Table

| Factor                  | Details                                                                 |
|-------------------------|-------------------------------------------------------------------------|
| **Triggers**            | Schedule, CPU usage, memory usage, incoming requests                    |
| **Definition**          | Cloud system adjusting resources based on demand                        |
| **Azure App Service**   | Monitors resource metrics, adds/removes web servers                     |
| **Rules**               | Thresholds for metrics triggering autoscale events                      |
| **Elasticity**          | Useful for fluctuating activity, e.g., holidays                         |
| **Fault Tolerance**     | Ensures service availability                                            |
| **Resource Processing** | Manual scaling preferred for resource-intensive tasks                   |
| **Long-term Growth**    | Manual scaling more cost-effective for predictable growth               |
| **Instance Count**      | Fewer instances = less capacity to handle workload increases            |
| **Purpose**                | Adjusts resources based on demand to handle peak times and manage costs                       |
| **Methods**                | Metric-based or schedule-based scaling                                                        |
| **App Service Plan**       | Defines hardware instances; has instance limits                                               |
| **Metric-Based Scaling**   | Uses metrics like CPU, memory, disk queue length, HTTP queue length, data in/out              |
| **Schedule-Based Scaling** | Scales to specific instance count based on time or date                                       |
| **Metric Analysis**        | Time grain and duration used for aggregating and analyzing metric values                      |
| **Autoscale Actions**      | Scale-out (increase instances), Scale-in (reduce instances), cool down period between actions  |
| **Rule Pairing**           | Define both scale-out and scale-in rules for the same metric                                  |
| **Rule Combining**         | Multiple rules in a condition; scale-out if any met, scale-in if all met                      |


| Action                       | Details                                                                                         |
|------------------------------|-------------------------------------------------------------------------------------------------|
| **Enable Autoscale**         | Navigate to Scale out (App Service plan), select Custom autoscale                              |
| **Pricing Tiers Requirement**| Scale up to S1 or P level production tiers for autoscaling                                      |
| **Default Scale Condition**  | Active when no other conditions apply                                                           |
| **Custom Scale Conditions**  | Metric-based or instance count-based, can include schedules                                     |


| Best Practice                       | Details                                                                 |
|-------------------------------------|-------------------------------------------------------------------------|
| **Distinguish Max/Min Values**      | Ensure margin between max and min instance counts                       |
| **Choose Appropriate Statistics**   | Use metrics like Average for diagnostics                                |
| **Set Practical Thresholds**        | Different thresholds for scale-out and scale-in                         |
| **Avoid Conflicting Rules**         | Use separate thresholds for scale-out and scale-in                      |
| **Estimate Scale-In Effects**       | Prevent flapping by estimating impact of scaling in                     |
| **Use Multiple Rules Wisely**       | Scale-out if any rule met, scale-in if all rules met                    |
| **Safe Default Instance Count**     | Set a default count safe for workloads                                  |
| **Configure Notifications**         | Use Activity Log alerts for monitoring autoscale actions and health     |
| **Create Scale Rules**       | Add custom rules, define criteria for triggering autoscale actions                              |
| **Monitor Activity**         | Use Run history chart to track instance variations and correlate with resource utilization      |
