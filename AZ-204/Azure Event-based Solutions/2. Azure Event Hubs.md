# Discover Azure Event Hubs

Azure Event Hubs is a highly scalable data streaming platform and event ingestion service, often referred to as the "front door" for an event pipeline. It acts as an event ingestor, decoupling event production from event consumption.

## Key Features of Azure Event Hubs

| Feature                    | Description                                                                                                      |
|----------------------------|------------------------------------------------------------------------------------------------------------------|
| Fully managed PaaS         | Event Hubs is a fully managed Platform-as-a-Service (PaaS), requiring minimal configuration or management.        |
| Real-time and batch processing | Uses a partitioned consumer model for concurrent stream processing and control over processing speed.           |
| Capture event data         | Captures data in near-real time in Azure Blob storage or Azure Data Lake Storage for long-term retention.          |
| Scalable                   | Provides scaling options like Auto-inflate to adjust throughput units based on usage needs.                       |
| Rich ecosystem             | Supports Apache Kafka ecosystems, enabling Kafka clients and applications to interact with Event Hubs.            |

## Key Concepts

### Components

- **Event Hubs Client**: The primary interface for developers, with different clients for publishing or consuming events.
- **Event Hubs Producer**: A client that sends telemetry data, diagnostics information, usage logs, etc., to Event Hubs.
- **Event Hubs Consumer**: A client that reads and processes data from Event Hubs, often involving aggregation, computation, filtering, and storage.

### Architecture Elements

- **Partition**: An ordered sequence of events within Event Hubs, used for data organization and parallel processing. The number of partitions is fixed at creation.
- **Consumer Group**: A view of the entire Event Hubs, allowing multiple consuming applications to read the event stream independently. Each partition can have up to five concurrent readers, but it's recommended to have only one active consumer per partition and consumer group pairing.
- **Event Receivers**: Entities that read event data from Event Hubs via AMQP 1.0 session or Kafka protocol 1.0 and later.
- **Throughput Units**: Pre-purchased units of capacity controlling the throughput of Event Hubs.

### Stream Processing Architecture

Azure Event Hubs provides a partitioned consumer pattern where each consumer reads a specific subset of the message stream, ensuring efficient and organized data processing.

<img src="https://learn.microsoft.com/en-in/training/wwl-azure/azure-event-hubs/media/event-hubs-stream-processing.png" alt="Static Website Configuration Screenshot" width="500" height="300"> 

# Explore Event Hubs Capture

Azure Event Hubs Capture allows you to automatically store streaming data in Event Hubs into Azure Blob Storage or Azure Data Lake Storage. This feature provides flexibility in specifying a time or size interval for data capture, scales with Event Hubs throughput units, and requires no administrative overhead.


<img src="https://learn.microsoft.com/en-in/training/wwl-azure/azure-event-hubs/media/event-hubs-capture.png" alt="Static Website Configuration Screenshot" width="500" height="300"> 


## Key Features of Event Hubs Capture

- **Automatic Capture**: Streams data into Azure Blob Storage or Azure Data Lake Storage.
- **Time/Size Interval**: Allows specification of capture intervals based on time or size.
- **Scalability**: Scales automatically with Event Hubs throughput units.
- **No Administrative Costs**: Fast setup with no additional costs for administration.
- **Real-time and Batch Processing**: Supports both real-time and batch-based pipelines.

## How Event Hubs Capture Works

- **Time-Retention Durable Buffer**: Similar to a distributed log, Event Hubs provides a partitioned consumer model for scalable data ingestion.
- **Partitioned Consumer Model**: Each partition is an independent data segment consumed separately.
- **Data Retention**: Configurable retention period to ensure data does not overflow.
- **Storage Options**: Choose between Azure Blob Storage and Azure Data Lake Store for captured data storage.
- **Storage Flexibility**: Accounts can be in the same or different regions as the Event Hub.
- **Data Format**: Captured data is stored in Apache Avro format, which is compact, fast, and provides rich data structures.

## Capture Windowing

- **Window Configuration**: Minimum size and time configuration with a "first wins policy".
- **Independent Partition Capture**: Each partition captures and writes data independently.
- **Storage Naming Convention**: Data is stored with a specific naming format:
  ```
  {Namespace}/{EventHub}/{PartitionId}/{Year}/{Month}/{Day}/{Hour}/{Minute}/{Second}
  ```
  Example:
  ```
  https://mystorageaccount.blob.core.windows.net/mycontainer/mynamespace/myeventhub/0/2017/12/08/03/03/17.avro
  ```

## Scaling to Throughput Units

- **Throughput Units**: Control traffic with a single unit allowing 1 MB/s or 1000 events/s of ingress and double that for egress.
- **Quota Management**: Standard Event Hubs can have 1-20 throughput units, with options for more via support requests.
- **Capture Efficiency**: Event Hubs Capture bypasses throughput unit egress quotas, saving egress capacity for other processing readers like Stream Analytics or Spark.
- **Automatic Operation**: Runs automatically upon the first event and continues to run. Writes empty files during inactivity to maintain a predictable cadence.


# Scale Your Event Processing Application with Azure Event Hubs

Scaling your event processing application involves running multiple instances and balancing the load among them. The key to this scalability in Event Hubs is the partitioned consumer model, which facilitates high scale by enabling parallelism and removing contention bottlenecks.

## Key Components for Scaling

### EventProcessorClient (for .NET and Java)
- Manages the distribution and balancing of work.
- Automatically handles partition ownership and load balancing.

### EventHubConsumerClient (for Python and JavaScript)
- Similar to EventProcessorClient, it manages partition ownership and event processing.

## Example Scenario

Consider a home security company monitoring 100,000 homes with various sensors:
- Sensors push data to an event hub configured with 16 partitions.
- The consumer application reads these events, aggregates the data, and stores it in a blob for web display.

### Requirements for the Consumer Application

1. **Scale**: Multiple consumers, each handling several Event Hubs partitions.
2. **Load Balance**: Dynamic increase or reduction of consumers to adapt to changes in event volume.
3. **Seamless Resume on Failures**: Other consumers take over partitions from a failed consumer, resuming from the last checkpoint.
4. **Consume Events**: Efficiently process and utilize the events.

## Event Processor or Consumer Client

Azure Event Hubs SDKs simplify the development of scalable consumer applications:
- **EventProcessorClient** for .NET and Java.
- **EventHubConsumerClient** for Python and JavaScript.

### Partition Ownership Tracking

- Each event processor instance claims ownership of partitions and updates a checkpoint store.
- Periodic updates to the store help balance the load among active processors.

### Receive Messages

- Functions specified for processing events and errors handle each event delivered from a specific partition.
- For guaranteed processing, implement retry logic.

### Checkpointing

- Checkpointing marks the last successfully processed event within a partition.
- Provides resilience by enabling other processors to resume from the last committed checkpoint.

## Best Practices

1. **Fast Processing**: Minimize processing within event handlers. Delegate heavy tasks to separate consumer groups.
2. **Thread Safety**: Ensure shared state across partitions is synchronized.

## Example Implementation

### Setting Up EventProcessorClient (for .NET)

```csharp
var eventProcessorClient = new EventProcessorClient(
    checkpointStore: new BlobCheckpointStore(blobContainerClient),
    consumerGroup: EventHubConsumerClient.DefaultConsumerGroupName,
    fullyQualifiedNamespace: "<EVENT_HUBS_NAMESPACE>",
    eventHubName: "<EVENT_HUB_NAME>",
    credential: new DefaultAzureCredential());

eventProcessorClient.ProcessEventAsync += async eventArgs =>
{
    try
    {
        // Process the event
        Console.WriteLine($"Event received: {eventArgs.Data.EventBody}");

        // Update checkpoint
        await eventArgs.UpdateCheckpointAsync(eventArgs.CancellationToken);
    }
    catch (Exception ex)
    {
        Console.WriteLine($"Error processing event: {ex.Message}");
    }
};

eventProcessorClient.ProcessErrorAsync += async eventArgs =>
{
    Console.WriteLine($"Error on partition {eventArgs.PartitionId}: {eventArgs.Exception.Message}");
};

// Start the processing
await eventProcessorClient.StartProcessingAsync();

// Stop the processing when needed
await eventProcessorClient.StopProcessingAsync();
```

### Setting Up EventHubConsumerClient (for Python)

```python
from azure.eventhub import EventHubConsumerClient

def on_event(partition_context, event):
    print("Received event: ", event.body_as_str())
    partition_context.update_checkpoint(event)

def on_error(partition_context, error):
    print("Error on partition {}: {}".format(partition_context.partition_id, error))

consumer_client = EventHubConsumerClient.from_connection_string(
    conn_str="EVENT_HUBS_CONNECTION_STRING",
    consumer_group="$Default",
    eventhub_name="EVENT_HUB_NAME",
)

consumer_client.receive(
    on_event=on_event,
    on_error=on_error,
)

# Close the consumer client when done
consumer_client.close()
```

# Control Access to Events in Azure Event Hubs

Azure Event Hubs supports both Microsoft Entra ID (formerly Azure AD) and shared access signatures (SAS) for handling authentication and authorization.

## Azure Built-in Roles for Event Hubs

Azure provides the following built-in roles for authorizing access to Event Hubs data using Microsoft Entra ID and OAuth:

| Role                        | Description                                |
|-----------------------------|--------------------------------------------|
| Azure Event Hubs Data Owner | Complete access to Event Hubs resources.   |
| Azure Event Hubs Data Sender| Send access to Event Hubs resources.       |
| Azure Event Hubs Data Receiver | Receiving access to Event Hubs resources. |

## Authorization Methods

### Authorize with Managed Identities

1. **Configure Azure RBAC**:
   - Assign Azure roles to the managed identity.
   - Managed identity is granted appropriate access to Event Hubs data at the configured scope.

### Authorize with Microsoft Entra ID

1. **OAuth 2.0 Access Token**:
   - Request an access token from the Microsoft identity platform.
   - Microsoft Entra ID authenticates the security principal.
   - On successful authentication, an access token is returned to the application.
   - The application uses this access token to authorize requests to Azure Event Hubs.

### Authorize with Shared Access Signatures (SAS)

#### For Event Hubs Publishers

1. **Define Virtual Endpoint**:
   - Each event publisher is a virtual endpoint within an Event Hub.
   - Publishers are used only to send messages, not to receive.

2. **Token Assignment**:
   - Each client is assigned a unique token.
   - A client with a token can only send to one publisher.
   - Shared tokens enable clients to share the same publisher.

3. **Token Security**:
   - All tokens are signed with shared access signature keys.
   - Clients operate on tokens until they expire, unaware of the key.

#### For Event Hubs Consumers

1. **Token Authentication**:
   - Clients must have manage rights or listen privileges on the Event Hubs namespace, event hub instance, or topic.
   - Data consumption is via consumer groups.
   - SAS policy provides granular scope at the entity level, not the consumer level.

## Summary

Azure Event Hubs provides flexible and secure access control mechanisms through Microsoft Entra ID and SAS. These mechanisms allow for granular and role-based access control, ensuring secure and efficient management of Event Hubs data.

## Example: Assigning Roles with Azure CLI

### Assign Azure Event Hubs Data Sender Role to a Managed Identity

```bash
az role assignment create \
  --assignee <managed-identity-principal-id> \
  --role "Azure Event Hubs Data Sender" \
  --scope /subscriptions/<subscription-id>/resourceGroups/<resource-group>/providers/Microsoft.EventHub/namespaces/<namespace-name>
```

### Request OAuth 2.0 Access Token (Python Example)

```python
from azure.identity import DefaultAzureCredential
from azure.eventhub import EventHubProducerClient

credential = DefaultAzureCredential()
client = EventHubProducerClient(
    fully_qualified_namespace="<namespace>.servicebus.windows.net",
    eventhub_name="<eventhub-name>",
    credential=credential
)

# Use the client to send events
```

### Generate Shared Access Signature (SAS) for Event Publisher

```bash
az eventhubs eventhub authorization-rule keys list \
  --resource-group <resource-group> \
  --namespace-name <namespace-name> \
  --eventhub-name <eventhub-name> \
  --name <authorization-rule-name>
```

### Use SAS Token for Sending Events (Python Example)

```python
from azure.eventhub import EventHubProducerClient, EventData

client = EventHubProducerClient.from_connection_string(
    conn_str="Endpoint=sb://<namespace>.servicebus.windows.net/;SharedAccessKeyName=<key-name>;SharedAccessKey=<key>;EntityPath=<eventhub-name>"
)

event_data_batch = client.create_batch()
event_data_batch.add(EventData('First event'))
event_data_batch.add(EventData('Second event'))

client.send_batch(event_data_batch)
```

# Common Operations with the Event Hubs Client Library

This guide provides examples of common operations using the Azure.Messaging.EventHubs library to interact with Azure Event Hubs.

## Inspect Event Hubs

### Example: Get Partition IDs

To inspect the partitions of an Event Hub, you can use the `EventHubProducerClient` to get the partition IDs.

```csharp
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

await using (var producer = new EventHubProducerClient(connectionString, eventHubName))
{
    string[] partitionIds = await producer.GetPartitionIdsAsync();
}
```

## Publish Events to Event Hubs

### Example: Publish Events Using Automatic Routing

Create an `EventHubProducerClient` and publish events in batches.

```csharp
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

await using (var producer = new EventHubProducerClient(connectionString, eventHubName))
{
    using EventDataBatch eventBatch = await producer.CreateBatchAsync();
    eventBatch.TryAdd(new EventData(new BinaryData("First")));
    eventBatch.TryAdd(new EventData(new BinaryData("Second")));

    await producer.SendAsync(eventBatch);
}
```

## Read Events from an Event Hub

### Example: Read Events Using an Iterator

Create an `EventHubConsumerClient` to read events from an Event Hub.

```csharp
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

string consumerGroup = EventHubConsumerClient.DefaultConsumerGroupName;

await using (var consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName))
{
    using var cancellationSource = new CancellationTokenSource();
    cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

    await foreach (PartitionEvent receivedEvent in consumer.ReadEventsAsync(cancellationSource.Token))
    {
        // Process the event
    }
}
```

## Read Events from a Specific Partition

### Example: Read All Events for the First Partition

Specify where in the event stream to begin receiving events for a specific partition.

```csharp
var connectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";

string consumerGroup = EventHubConsumerClient.DefaultConsumerGroupName;

await using (var consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName))
{
    EventPosition startingPosition = EventPosition.Earliest;
    string partitionId = (await consumer.GetPartitionIdsAsync()).First();

    using var cancellationSource = new CancellationTokenSource();
    cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

    await foreach (PartitionEvent receivedEvent in consumer.ReadEventsFromPartitionAsync(partitionId, startingPosition, cancellationSource.Token))
    {
        // Process the event
    }
}
```

## Process Events Using an Event Processor Client

For production scenarios, use `EventProcessorClient` for reading and processing events.

### Example: Use EventProcessorClient with Azure Storage Blobs

Set up an `EventProcessorClient` with a BlobContainerClient for state persistence.

```csharp
var cancellationSource = new CancellationTokenSource();
cancellationSource.CancelAfter(TimeSpan.FromSeconds(45));

var storageConnectionString = "<< CONNECTION STRING FOR THE STORAGE ACCOUNT >>";
var blobContainerName = "<< NAME OF THE BLOB CONTAINER >>";

var eventHubsConnectionString = "<< CONNECTION STRING FOR THE EVENT HUBS NAMESPACE >>";
var eventHubName = "<< NAME OF THE EVENT HUB >>";
var consumerGroup = "<< NAME OF THE EVENT HUB CONSUMER GROUP >>";

Task processEventHandler(ProcessEventArgs eventArgs) => Task.CompletedTask;
Task processErrorHandler(ProcessErrorEventArgs eventArgs) => Task.CompletedTask;

var storageClient = new BlobContainerClient(storageConnectionString, blobContainerName);
var processor = new EventProcessorClient(storageClient, consumerGroup, eventHubsConnectionString, eventHubName);

processor.ProcessEventAsync += processEventHandler;
processor.ProcessErrorAsync += processErrorHandler;

await processor.StartProcessingAsync();

try
{
    // Allow processing to take place
    await Task.Delay(Timeout.Infinite, cancellationSource.Token);
}
catch (TaskCanceledException)
{
    // Expected when the delay is canceled
}

try
{
    await processor.StopProcessingAsync();
}
finally
{
    // Prevent leaks by removing handlers
    processor.ProcessEventAsync -= processEventHandler;
    processor.ProcessErrorAsync -= processErrorHandler;
}
```

## Summary

- Azure Event Hubs is a robust, scalable platform designed to handle large volumes of event data. It provides real-time and batch processing capabilities, seamless integration with Apache Kafka, and efficient data organization through partitions and consumer groups. This makes it an ideal choice for building event-driven architectures and processing high-throughput event streams.
- Azure Event Hubs Capture is a powerful feature that enables seamless integration of real-time and batch processing pipelines. By leveraging automatic capture, scalable throughput units, and flexible storage options, Event Hubs Capture ensures efficient and reliable data ingestion and storage.
- Scaling an event processing application in Azure Event Hubs involves leveraging the partitioned consumer model, using EventProcessorClient or EventHubConsumerClient to manage load balancing, checkpointing, and seamless failover. By following best practices and utilizing Azure Event Hubs SDKs, you can efficiently build a robust and scalable event-driven architecture.
